{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import namedtuple\n",
    "import keras_tuner as kt\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebase_path = '/data/home/wpw035/Codebase'\n",
    "sys.path.insert(0, codebase_path) #add path to my codebase models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Learning_curve' from '/data/home/wpw035/Drug_response_prediction/DRP-alpha-preliminary-results/Unseen_cell_line_testing/Learning_curve.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my moudles\n",
    "from DRP_utils import data_preprocessing as dp_nb\n",
    "reload(dp_nb)\n",
    "from DRP_utils import model_selection as ms_nb\n",
    "reload(ms_nb)\n",
    "from DRP_utils import testing as t_nb\n",
    "reload(t_nb)\n",
    "import Data_imports as di_nb\n",
    "reload(di_nb)\n",
    "import pairs_train_test_split as  tts_nb\n",
    "reload(tts_nb)\n",
    "import Learning_curve as lc_nb\n",
    "reload(lc_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing prot values 0.386335609896865\n",
      "num non overlapping prot and target cls: 10\n",
      "num non overlapping rna prot and target cls: 91\n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "prot, rna, one_hot_cls, one_hot_drugs, ic50_df1 = di_nb.read_input_data()\n",
    "_all_cls = prot.index\n",
    "_all_drugs = ic50_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((877, 8457), (877, 17417), (877, 877), (345, 345))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot.shape, rna.shape, one_hot_cls.shape, one_hot_drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (FS) and creating data for each drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((263375, 908), (263375, 345), 263375)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in landmark genes for fs and find landmarks that overlap with rna data\n",
    "landmark_genes = pd.read_csv(\n",
    "    f'{codebase_path}/downloaded_data_small/landmark_genes_LINCS.txt',sep='\\t')\n",
    "landmark_genes.index = landmark_genes['Symbol']\n",
    "\n",
    "dft = pd.DataFrame(rna.columns.dropna())\n",
    "dft.index = rna.columns.dropna()\n",
    "dft = dft[dft.duplicated() == False]\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), dft)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create input data for each drug\n",
    "x_all, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    rna[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "x_all = x_all.astype(np.float32)\n",
    "x_drug = x_drug.astype(np.float16)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all.index + '::' + x_drug.index\n",
    "x_all.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "\n",
    "x_all.shape, x_drug.shape, len(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prot FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the same landmark genes, that were used for fs for rna data\n",
    "#for fs with prot data\n",
    "#find overlapping landmark genes and prot features\n",
    "dft = pd.DataFrame(prot.columns.dropna())\n",
    "dft.index = prot.columns.dropna()\n",
    "dft = dft[dft.duplicated() == False]\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), dft)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create prot data for all drugs\n",
    "x_all_prot, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    prot[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all_prot.index + '::' + x_drug.index \n",
    "x_all_prot.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "\n",
    "x_all_prot = x_all_prot.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one hot data for all drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hot, x_drug_hot, y_hot = dp_nb.create_all_drugs(\n",
    "    one_hot_cls, one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "cls_drugs_index_hot = x_hot.index + '::' + x_drug_hot.index \n",
    "\n",
    "x_hot.index = cls_drugs_index_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model buliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_shape=None\n",
    "def build_cnn_kt(hp):\n",
    "    if _input_shape == None:\n",
    "        raise Exception('add input shape dim')\n",
    "    phos_input = layers.Input(shape=(_input_shape, 1))\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts', 8, 32, 8), kernel_size=16, \n",
    "        activation='relu')(phos_input)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts',8, 32, 8), kernel_size=8, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    drug_input = layers.Input(shape = (xdrug_train.shape[1]))\n",
    "    concatenated = layers.concatenate([x, drug_input])\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(concatenated)\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(hidd)\n",
    "    output_tensor = layers.Dense(1)(hidd)\n",
    "    model = tf.keras.Model([phos_input,drug_input], output_tensor)\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=hp.Choice('lr', [1e-4, 1e-3, 1e-2]))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.metrics.mean_squared_error, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cls in sets, relative to all clsbefore mising values are removed\n",
      "train fraction 0.7993158494868872, test fraction 0.10034207525655645,validaiton fraciton 0.10034207525655645\n",
      "------\n",
      "Fraction of cls in sets, relative to all cl drug pairs, aftermising values are removed\n",
      "train fraction 0.6972253895857089, test fraction0.08817939946788293, validaiton fraciton 0.0850693239469205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     2,      3,      4,      5,      6,      8,     10,     13,\n",
       "           16,     20,     26,     33,     42,     53,     67,     85,\n",
       "          108,    136,    173,    219,    277,    350,    443,    560,\n",
       "          708,    896,   1133,   1433,   1813,   2293,   2900,   3668,\n",
       "         4638,   5866,   7419,   9383,  11867,  15008,  18980,  24004,\n",
       "        30358,  38393,  48555,  61407,  77660,  98216, 124212, 157089,\n",
       "       198668, 210956])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to get train size\n",
    "rand_seed = 1\n",
    "pairs_with_truth_vals =  y_list.index\n",
    "train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "    rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals)\n",
    "\n",
    "#rna test train selection\n",
    "x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "\n",
    "#set train size search space. \n",
    "lg_space = np.logspace(1, 17.6, base=2.0).astype(int)\n",
    "lg_space = np.append(lg_space, len(x_train_rna))\n",
    "lg_space = np.unique(lg_space)\n",
    "lg_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_space = lg_space[: 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 of 10\n",
      "Fraction of cls in sets, relative to all clsbefore mising values are removed\n",
      "train fraction 0.7993158494868872, test fraction 0.10034207525655645,validaiton fraciton 0.10034207525655645\n",
      "------\n",
      "Fraction of cls in sets, relative to all cl drug pairs, aftermising values are removed\n",
      "train fraction 0.6935567563994514, test fraction0.08740270685637797, validaiton fraciton 0.08951464974468296\n"
     ]
    }
   ],
   "source": [
    "#Prot\n",
    "#finds a test train split then finds the learning curve\n",
    "#for that split. Repeats for mutiple (N) test train splits \n",
    "N = 10\n",
    "\n",
    "\n",
    "for run in range(N):\n",
    "    print(f'run {run} of {N}')\n",
    "    #test train split\n",
    "    rand_seed = 42 + run\n",
    "    pairs_with_truth_vals =  y_list.index\n",
    "    train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "        rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals)\n",
    "\n",
    "    #rna test train selection\n",
    "    x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "    x_val_rna = x_all.loc[val_pairs]\n",
    "    y_train, y_test = y_list[train_pairs], y_list[test_pairs]\n",
    "    y_val = y_list[val_pairs]\n",
    "    xdrug_train, xdrug_test = x_drug.loc[train_pairs], x_drug.loc[test_pairs]\n",
    "    xdrug_val = x_drug.loc[val_pairs]\n",
    "\n",
    "    #prot test train selection\n",
    "    x_train_prot, x_test_prot = x_all_prot.loc[train_pairs], x_all_prot.loc[test_pairs]\n",
    "    x_val_prot = x_all_prot.loc[val_pairs]\n",
    "\n",
    "    #one hot test train seleciton\n",
    "    x_train_hot, x_test_hot = x_hot.loc[train_pairs], x_hot.loc[test_pairs]\n",
    "    x_val_hot = x_hot.loc[val_pairs]\n",
    "\n",
    "\n",
    "    #consistencey checks\n",
    "    assert (x_train_hot.index == x_train_rna.index).all()\n",
    "    assert (x_test_hot.index == x_test_rna.index).all()\n",
    "    assert (x_val_hot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (x_train_prot.index == x_train_rna.index).all()\n",
    "    assert (x_test_prot.index == x_test_rna.index).all()\n",
    "    assert (x_val_prot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (y_train.index == x_train_rna.index).all()\n",
    "    assert (y_test.index == x_test_rna.index).all()\n",
    "    assert (xdrug_test.index == x_test_rna.index).all()\n",
    "\n",
    "    #inconsistencey checks\n",
    "    assert x_train_rna.shape[1] != x_train_prot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_prot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_prot.shape[1]\n",
    "\n",
    "    assert x_train_rna.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_hot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_hot.shape[1]\n",
    "\n",
    "    assert x_train_prot.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_prot.shape[1] != x_test_hot.shape[1]\n",
    "\n",
    "    #run the learning curve\n",
    "    _input_shape = x_train_prot.shape[1]\n",
    "    mse_r2_rna, bms, bhps = lc_nb.run_lc_ucl(\n",
    "        build_cnn_kt,\n",
    "        [x_train_prot, xdrug_train], \n",
    "        y_train, \n",
    "        [x_val_prot, xdrug_val], \n",
    "        y_val, \n",
    "        [x_test_prot, xdrug_test],\n",
    "        y_test, \n",
    "        lg_space, \n",
    "        num_trails=15,\n",
    "        epochs=100,\n",
    "        direc='UCL-del2')\n",
    "    \n",
    "    #save data\n",
    "    mse_r2_rna.to_csv(f'LC-metric-results/Prot/run{run}')\n",
    "    bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "    bhps_df.to_csv(f'Optimal-hyperparameters/Prot/run{run}df')\n",
    "    with open(f'Optimal-hyperparameters/Prot/run{run}.pkl', 'wb') as f:\n",
    "        pickle.dump(bhps, f)\n",
    "    model_path = f'optimal-models/Prot/run{run}/model_train_size_'\n",
    "    for train_size, model in zip(lg_space, bms):\n",
    "        model.save(model_path + str(train_size)) \n",
    "    np.savetxt(f'test_train_cls/train_pairs{run}', train_pairs, fmt='%s')\n",
    "    np.savetxt(f'test_train_cls/test_pairs{run}', test_pairs, fmt='%s')\n",
    "    np.savetxt(f'test_train_cls/val_pairs{run}', val_pairs, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662969015.5373104"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - t1 / (60 * 60 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.05"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_space[0 : 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x2ba3a5673c40>,\n",
       " <keras.engine.functional.Functional at 0x2ba43edd1b80>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "mse_r2_rna.to_csv(f'LC-metric-results/RNA/run{0}')\n",
    "bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "bhps_df.to_csv(f'Optimal-hyperparameter/RNA/run{0}df')\n",
    "with open(f'Optimal-hyperparameter/RNA/run{0}.pkl', 'wb') as f:\n",
    "    pickle.dump(bhps, f)\n",
    "model_path = f'optimal-models/run{0}/train_size'\n",
    "for i, model in enumerate(bms):\n",
    "    model.save(model_path + str(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 17:06:11.322256: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: optimal-models/run0/0/assets\n",
      "INFO:tensorflow:Assets written to: optimal-models/run0/1/assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filts</th>\n",
       "      <th>units</th>\n",
       "      <th>units_hid</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filts  units  units_hid     lr\n",
       "0     16    224        224  0.010\n",
       "1     24     96         96  0.001"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([bhp.values for bhp in bhps] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPUforge",
   "language": "python",
   "name": "tfgpuforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
