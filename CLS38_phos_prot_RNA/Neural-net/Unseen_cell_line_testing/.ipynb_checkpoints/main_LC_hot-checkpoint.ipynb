{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import namedtuple\n",
    "import keras_tuner as kt\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebase_path = '/data/home/wpw035/Codebase'\n",
    "sys.path.insert(0, codebase_path) #add path to my codebase models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Learning_curve' from '/data/home/wpw035/Drug_response_prediction/DRP-alpha-preliminary-results/Unseen_cell_line_testing/Learning_curve.py'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my moudles\n",
    "from DRP_utils import data_preprocessing as dp_nb\n",
    "reload(dp_nb)\n",
    "from DRP_utils import model_selection as ms_nb\n",
    "reload(ms_nb)\n",
    "from DRP_utils import testing as t_nb\n",
    "reload(t_nb)\n",
    "import Data_imports as di_nb\n",
    "reload(di_nb)\n",
    "import pairs_train_test_split as  tts_nb\n",
    "reload(tts_nb)\n",
    "import Learning_curve as lc_nb\n",
    "reload(lc_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing prot values 0.386335609896865\n",
      "num non overlapping prot and target cls: 10\n",
      "num non overlapping rna prot and target cls: 91\n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "prot, rna, one_hot_cls, one_hot_drugs, ic50_df1 = di_nb.read_input_data()\n",
    "_all_cls = prot.index\n",
    "_all_drugs = ic50_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((877, 8457), (877, 17417), (877, 877), (345, 345))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot.shape, rna.shape, one_hot_cls.shape, one_hot_drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (FS) and creating data for each drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((263375, 908), (263375, 345), 263375)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in landmark genes for fs and find landmarks that overlap with rna data\n",
    "landmark_genes = pd.read_csv(\n",
    "    f'{codebase_path}/downloaded_data_small/landmark_genes_LINCS.txt',sep='\\t')\n",
    "landmark_genes.index = landmark_genes['Symbol']\n",
    "\n",
    "dft = pd.DataFrame(rna.columns.dropna())\n",
    "dft.index = rna.columns.dropna()\n",
    "dft = dft[dft.duplicated() == False]\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), dft)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create input data for each drug\n",
    "x_all, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    rna[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "x_all = x_all.astype(np.float32)\n",
    "x_drug = x_drug.astype(np.float16)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all.index + '::' + x_drug.index\n",
    "x_all.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "\n",
    "x_all.shape, x_drug.shape, len(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prot FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the same landmark genes, that were used for fs for rna data\n",
    "#for fs with prot data\n",
    "#find overlapping landmark genes and prot features\n",
    "dft = pd.DataFrame(prot.columns.dropna())\n",
    "dft.index = prot.columns.dropna()\n",
    "dft = dft[dft.duplicated() == False]\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), dft)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create prot data for all drugs\n",
    "x_all_prot, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    prot[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all_prot.index + '::' + x_drug.index \n",
    "x_all_prot.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "\n",
    "x_all_prot = x_all_prot.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one hot data for all drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hot, x_drug_hot, y_hot = dp_nb.create_all_drugs(\n",
    "    one_hot_cls, one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "cls_drugs_index_hot = x_hot.index + '::' + x_drug_hot.index \n",
    "\n",
    "x_hot.index = cls_drugs_index_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model buliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_shape=None\n",
    "def build_cnn_kt(hp):\n",
    "    if _input_shape == None:\n",
    "        raise Exception('add input shape dim')\n",
    "    phos_input = layers.Input(shape=(_input_shape, 1))\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts', 8, 32, 8), kernel_size=16, \n",
    "        activation='relu')(phos_input)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts',8, 32, 8), kernel_size=8, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    drug_input = layers.Input(shape = (xdrug_train.shape[1]))\n",
    "    concatenated = layers.concatenate([x, drug_input])\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(concatenated)\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(hidd)\n",
    "    output_tensor = layers.Dense(1)(hidd)\n",
    "    model = tf.keras.Model([phos_input,drug_input], output_tensor)\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=hp.Choice('lr', [1e-4, 1e-3, 1e-2]))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.metrics.mean_squared_error, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     2,      3,      4,      5,      6,      8,     10,     13,\n",
       "           16,     20,     26,     33,     42,     53,     67,     85,\n",
       "          108,    136,    173,    219,    277,    350,    443,    560,\n",
       "          708,    896,   1133,   1433,   1813,   2293,   2900,   3668,\n",
       "         4638,   5866,   7419,   9383,  11867,  15008,  18980,  24004,\n",
       "        30358,  38393,  48555,  61407,  77660,  98216, 124212, 157089,\n",
       "       198668, 209846])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set train size search space. \n",
    "lg_space = np.logspace(1, 17.6, base=2.0).astype(int)\n",
    "lg_space = np.append(lg_space, len(x_train_rna))\n",
    "lg_space = np.unique(lg_space)\n",
    "lg_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 01m 47s]\n",
      "val_loss: 1.713757872581482\n",
      "\n",
      "Best val_loss So Far: 1.5501519441604614\n",
      "Total elapsed time: 00h 04m 41s\n",
      "\n",
      "Search: Running Trial #5\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "filts             |16                |24                \n",
      "units             |160               |224               \n",
      "units_hid         |192               |192               \n",
      "lr                |0.0001            |0.0001            \n",
      "\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 4s 8ms/step - loss: 6.6369 - mae: 1.9976 - val_loss: 6.2294 - val_mae: 1.9266\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 5.7817 - mae: 1.8449 - val_loss: 5.6085 - val_mae: 1.7231\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 4.0197 - mae: 1.4983 - val_loss: 3.0837 - val_mae: 1.3437\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 2.3923 - mae: 1.1424 - val_loss: 2.1453 - val_mae: 1.0876\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.8384 - mae: 1.0059 - val_loss: 1.9069 - val_mae: 1.0291\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.6502 - mae: 0.9540 - val_loss: 1.9457 - val_mae: 1.0639\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.5681 - mae: 0.9308 - val_loss: 1.8001 - val_mae: 1.0072\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.5235 - mae: 0.9166 - val_loss: 1.9540 - val_mae: 1.0713\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.4900 - mae: 0.9062 - val_loss: 1.7414 - val_mae: 0.9871\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.4669 - mae: 0.8986 - val_loss: 1.7898 - val_mae: 1.0016\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.4486 - mae: 0.8923 - val_loss: 1.7214 - val_mae: 0.9751\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.4298 - mae: 0.8859 - val_loss: 1.6870 - val_mae: 0.9702\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.4131 - mae: 0.8805 - val_loss: 1.7093 - val_mae: 0.9737\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.3915 - mae: 0.8729 - val_loss: 1.6848 - val_mae: 0.9685\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.3717 - mae: 0.8646 - val_loss: 1.7077 - val_mae: 0.9742\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.3498 - mae: 0.8584 - val_loss: 1.7468 - val_mae: 0.9886\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.3263 - mae: 0.8504 - val_loss: 1.7079 - val_mae: 0.9769\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.3063 - mae: 0.8434 - val_loss: 1.6349 - val_mae: 0.9477\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.2840 - mae: 0.8360 - val_loss: 1.6348 - val_mae: 0.9475\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.2652 - mae: 0.8285 - val_loss: 1.7090 - val_mae: 0.9802\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.2495 - mae: 0.8231 - val_loss: 1.6962 - val_mae: 0.9725\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.2317 - mae: 0.8165 - val_loss: 1.6339 - val_mae: 0.9522\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.2144 - mae: 0.8110 - val_loss: 1.7696 - val_mae: 1.0049\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.2010 - mae: 0.8058 - val_loss: 1.6025 - val_mae: 0.9405\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.1834 - mae: 0.7997 - val_loss: 1.5890 - val_mae: 0.9364\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.1678 - mae: 0.7931 - val_loss: 1.6943 - val_mae: 0.9803\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.1560 - mae: 0.7890 - val_loss: 1.6005 - val_mae: 0.9407\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.1426 - mae: 0.7830 - val_loss: 1.5587 - val_mae: 0.9270\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.1224 - mae: 0.7771 - val_loss: 1.6561 - val_mae: 0.9668\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 1.1077 - mae: 0.7711 - val_loss: 1.6376 - val_mae: 0.9564\n",
      "Epoch 31/100\n",
      "281/380 [=====================>........] - ETA: 0s - loss: 1.0935 - mae: 0.7662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNA\n",
    "#finds a test train split then finds the learning curve\n",
    "#for that split. Repeats for mutiple (N) test train splits \n",
    "N = 10\n",
    "#set train size search space. \n",
    "lg_space = np.logspace(1, 17.6, base=2.0).astype(int)\n",
    "lg_space = np.append(lg_space, len(x_train_rna))\n",
    "lg_space = np.unique(lg_space)\n",
    "\n",
    "\n",
    "for run in range(N):\n",
    "    print(f'run {run} of {N}')\n",
    "    #test train split\n",
    "    rand_seed = 42 + run\n",
    "    pairs_with_truth_vals =  y_list.index\n",
    "    train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "        rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals)\n",
    "\n",
    "    #rna test train selection\n",
    "    x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "    x_val_rna = x_all.loc[val_pairs]\n",
    "    y_train, y_test = y_list[train_pairs], y_list[test_pairs]\n",
    "    y_val = y_list[val_pairs]\n",
    "    xdrug_train, xdrug_test = x_drug.loc[train_pairs], x_drug.loc[test_pairs]\n",
    "    xdrug_val = x_drug.loc[val_pairs]\n",
    "\n",
    "    #prot test train selection\n",
    "    x_train_prot, x_test_prot = x_all_prot.loc[train_pairs], x_all_prot.loc[test_pairs]\n",
    "    x_val_prot = x_all_prot.loc[val_pairs]\n",
    "\n",
    "    #one hot test train seleciton\n",
    "    x_train_hot, x_test_hot = x_hot.loc[train_pairs], x_hot.loc[test_pairs]\n",
    "    x_val_hot = x_hot.loc[val_pairs]\n",
    "\n",
    "\n",
    "    #consistencey checks\n",
    "    assert (x_train_hot.index == x_train_rna.index).all()\n",
    "    assert (x_test_hot.index == x_test_rna.index).all()\n",
    "    assert (x_val_hot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (x_train_prot.index == x_train_rna.index).all()\n",
    "    assert (x_test_prot.index == x_test_rna.index).all()\n",
    "    assert (x_val_prot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (y_train.index == x_train_rna.index).all()\n",
    "    assert (y_test.index == x_test_rna.index).all()\n",
    "    assert (xdrug_test.index == x_test_rna.index).all()\n",
    "\n",
    "    #inconsistencey checks\n",
    "    assert x_train_rna.shape[1] != x_train_prot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_prot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_prot.shape[1]\n",
    "\n",
    "    assert x_train_rna.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_hot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_hot.shape[1]\n",
    "\n",
    "    assert x_train_prot.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_prot.shape[1] != x_test_hot.shape[1]\n",
    "\n",
    "    #run the learning curve\n",
    "    _input_shape = x_train_rna.shape[1]\n",
    "    mse_r2_rna, bms, bhps = lc_nb.run_lc_ucl(\n",
    "        build_cnn_kt,\n",
    "        [x_train_rna, xdrug_train], \n",
    "        y_train, \n",
    "        [x_val_rna, xdrug_val], \n",
    "        y_val, \n",
    "        [x_test_rna, xdrug_test],\n",
    "        y_test, \n",
    "        lg_space, \n",
    "        num_trails=15,\n",
    "        epochs=100,\n",
    "        direc='UCL-del1')\n",
    "    \n",
    "    #save data\n",
    "    mse_r2_rna.to_csv(f'LC-metric-results/RNA/run{run}')\n",
    "    bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "    bhps_df.to_csv(f'Optimal-hyperparameters/RNA/run{run}df')\n",
    "    with open(f'Optimal-hyperparameters/RNA/run{run}.pkl', 'wb') as f:\n",
    "        pickle.dump(bhps, f)\n",
    "    model_path = f'optimal-models/run{run}/model_train_size_'\n",
    "    for train_size, model in zip(lg_space, bms):\n",
    "        model.save(model_path + str(train_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662969015.5373104"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - t1 / (60 * 60 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 01m 08s]\n",
      "val_loss: 1.8371304273605347\n",
      "\n",
      "Best val_loss So Far: 1.7193182706832886\n",
      "Total elapsed time: 00h 25m 58s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "1.0\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "filts             |16                |?                 \n",
      "units             |192               |?                 \n",
      "units_hid         |64                |?                 \n",
      "lr                |0.0001            |?                 \n",
      "\n",
      "Epoch 1/100\n",
      "1553/1553 [==============================] - 12s 7ms/step - loss: 4.9867 - mae: 1.6813 - val_loss: 2.8361 - val_mae: 1.2285\n",
      "Epoch 2/100\n",
      "1553/1553 [==============================] - 11s 7ms/step - loss: 1.7724 - mae: 0.9840 - val_loss: 1.8805 - val_mae: 1.0471\n",
      "Epoch 3/100\n",
      "1553/1553 [==============================] - 10s 7ms/step - loss: 1.5378 - mae: 0.9181 - val_loss: 1.8836 - val_mae: 1.0429\n",
      "Epoch 4/100\n",
      "1553/1553 [==============================] - 10s 7ms/step - loss: 1.5048 - mae: 0.9062 - val_loss: 1.8690 - val_mae: 1.0383\n",
      "Epoch 5/100\n",
      "1553/1553 [==============================] - 11s 7ms/step - loss: 1.4816 - mae: 0.8979 - val_loss: 1.9940 - val_mae: 1.0703\n",
      "Epoch 6/100\n",
      " 361/1553 [=====>........................] - ETA: 8s - loss: 1.4553 - mae: 0.8908"
     ]
    }
   ],
   "source": [
    "#One hot \n",
    "#finds a test train split then finds the learning curve\n",
    "#for that split. Repeats for mutiple (N) test train splits \n",
    "N = 10\n",
    "#set train size search space. \n",
    "lg_space = np.logspace(1, 17.6, base=2.0).astype(int)\n",
    "lg_space = np.append(lg_space, len(x_train_rna))\n",
    "lg_space = np.unique(lg_space)\n",
    "\n",
    "\n",
    "for run in range(3, N):\n",
    "    print(f'run {run} of {N}')\n",
    "    #test train split\n",
    "    rand_seed = 42 + run\n",
    "    pairs_with_truth_vals =  y_list.index\n",
    "    train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "        rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals)\n",
    "\n",
    "    #rna test train selection\n",
    "    x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "    x_val_rna = x_all.loc[val_pairs]\n",
    "    y_train, y_test = y_list[train_pairs], y_list[test_pairs]\n",
    "    y_val = y_list[val_pairs]\n",
    "    xdrug_train, xdrug_test = x_drug.loc[train_pairs], x_drug.loc[test_pairs]\n",
    "    xdrug_val = x_drug.loc[val_pairs]\n",
    "\n",
    "    #prot test train selection\n",
    "    x_train_prot, x_test_prot = x_all_prot.loc[train_pairs], x_all_prot.loc[test_pairs]\n",
    "    x_val_prot = x_all_prot.loc[val_pairs]\n",
    "\n",
    "    #one hot test train seleciton\n",
    "    x_train_hot, x_test_hot = x_hot.loc[train_pairs], x_hot.loc[test_pairs]\n",
    "    x_val_hot = x_hot.loc[val_pairs]\n",
    "\n",
    "\n",
    "    #consistencey checks\n",
    "    assert (x_train_hot.index == x_train_rna.index).all()\n",
    "    assert (x_test_hot.index == x_test_rna.index).all()\n",
    "    assert (x_val_hot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (x_train_prot.index == x_train_rna.index).all()\n",
    "    assert (x_test_prot.index == x_test_rna.index).all()\n",
    "    assert (x_val_prot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (y_train.index == x_train_rna.index).all()\n",
    "    assert (y_test.index == x_test_rna.index).all()\n",
    "    assert (xdrug_test.index == x_test_rna.index).all()\n",
    "\n",
    "    #inconsistencey checks\n",
    "    assert x_train_rna.shape[1] != x_train_prot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_prot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_prot.shape[1]\n",
    "\n",
    "    assert x_train_rna.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_hot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_hot.shape[1]\n",
    "\n",
    "    assert x_train_prot.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_prot.shape[1] != x_test_hot.shape[1]\n",
    "    \n",
    "   \n",
    "    #run the learning curve\n",
    "    _input_shape = x_train_hot.shape[1]\n",
    "    mse_r2_rna, bms, bhps = lc_nb.run_lc_ucl(\n",
    "        build_cnn_kt,\n",
    "        [x_train_hot, xdrug_train], \n",
    "        y_train, \n",
    "        [x_val_hot, xdrug_val], \n",
    "        y_val, \n",
    "        [x_test_hot, xdrug_test],\n",
    "        y_test, \n",
    "        lg_space, \n",
    "        num_trails=15,\n",
    "        epochs=100,\n",
    "        direc='UCL-del1')\n",
    "    \n",
    "    #save data\n",
    "    mse_r2_rna.to_csv(f'LC-metric-results/One-hot/run{run}')\n",
    "    bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "    bhps_df.to_csv(f'Optimal-hyperparameters/One-hot/run{run}df')\n",
    "    with open(f'Optimal-hyperparameters/One-hot/run{run}.pkl', 'wb') as f:\n",
    "        pickle.dump(bhps, f)\n",
    "    model_path = f'optimal-models/run{run}/model_train_size_'\n",
    "    for train_size, model in zip(lg_space, bms):\n",
    "        model.save(model_path + str(train_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.05"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_space[0 : 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x2ba3a5673c40>,\n",
       " <keras.engine.functional.Functional at 0x2ba43edd1b80>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "mse_r2_rna.to_csv(f'LC-metric-results/RNA/run{0}')\n",
    "bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "bhps_df.to_csv(f'Optimal-hyperparameter/RNA/run{0}df')\n",
    "with open(f'Optimal-hyperparameter/RNA/run{0}.pkl', 'wb') as f:\n",
    "    pickle.dump(bhps, f)\n",
    "model_path = f'optimal-models/run{0}/train_size'\n",
    "for i, model in enumerate(bms):\n",
    "    model.save(model_path + str(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 17:06:11.322256: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: optimal-models/run0/0/assets\n",
      "INFO:tensorflow:Assets written to: optimal-models/run0/1/assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filts</th>\n",
       "      <th>units</th>\n",
       "      <th>units_hid</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filts  units  units_hid     lr\n",
       "0     16    224        224  0.010\n",
       "1     24     96         96  0.001"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([bhp.values for bhp in bhps] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPUforge",
   "language": "python",
   "name": "tfgpuforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
