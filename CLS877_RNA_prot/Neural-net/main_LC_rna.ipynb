{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import namedtuple\n",
    "import keras_tuner as kt\n",
    "import time\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebase_path = '/data/home/wpw035/Codebase'\n",
    "sys.path.insert(0, codebase_path) #add path to my codebase models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Learning_curve' from '/data/home/wpw035/Drug_response_prediction/DRP-alpha-preliminary-results/Unseen_cell_line_testing/Learning_curve.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my moudles\n",
    "from DRP_utils import data_preprocessing as dp_nb\n",
    "reload(dp_nb)\n",
    "from DRP_utils import model_selection as ms_nb\n",
    "reload(ms_nb)\n",
    "from DRP_utils import testing as t_nb\n",
    "reload(t_nb)\n",
    "import Data_imports as di_nb\n",
    "reload(di_nb)\n",
    "import pairs_train_test_split as  tts_nb\n",
    "reload(tts_nb)\n",
    "import Learning_curve as lc_nb\n",
    "reload(lc_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing prot values 0.386335609896865\n",
      "num non overlapping prot and target cls: 10\n",
      "num non overlapping rna prot and target cls: 91\n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "prot, rna, one_hot_cls, one_hot_drugs, ic50_df1 = di_nb.read_input_data()\n",
    "_all_cls = prot.index\n",
    "_all_drugs = ic50_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((877, 8457), (877, 17417), (877, 877), (345, 345))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot.shape, rna.shape, one_hot_cls.shape, one_hot_drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (FS) and creating data for each drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((263375, 908), (263375, 345), 263375)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in landmark genes for fs and find landmarks that overlap with rna data\n",
    "landmark_genes = pd.read_csv(\n",
    "    f'{codebase_path}/downloaded_data_small/landmark_genes_LINCS.txt',sep='\\t')\n",
    "landmark_genes.index = landmark_genes['Symbol']\n",
    "\n",
    "dft = pd.DataFrame(rna.columns.dropna())\n",
    "dft.index = rna.columns.dropna()\n",
    "dft = dft[dft.duplicated() == False]\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), dft)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create input data for each drug\n",
    "x_all, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    rna[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "x_all = x_all.astype(np.float32)\n",
    "x_drug = x_drug.astype(np.float16)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all.index + '::' + x_drug.index\n",
    "x_all.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "\n",
    "x_all.shape, x_drug.shape, len(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prot FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the same landmark genes, that were used for fs for rna data\n",
    "#for fs with prot data\n",
    "#find overlapping landmark genes and prot features\n",
    "dft = pd.DataFrame(prot.columns.dropna())\n",
    "dft.index = prot.columns.dropna()\n",
    "dft = dft[dft.duplicated() == False]\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), dft)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create prot data for all drugs\n",
    "x_all_prot, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    prot[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all_prot.index + '::' + x_drug.index \n",
    "x_all_prot.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "\n",
    "x_all_prot = x_all_prot.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one hot data for all drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hot, x_drug_hot, y_hot = dp_nb.create_all_drugs(\n",
    "    one_hot_cls, one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "cls_drugs_index_hot = x_hot.index + '::' + x_drug_hot.index \n",
    "\n",
    "x_hot.index = cls_drugs_index_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model buliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_shape=None\n",
    "def build_cnn_kt(hp):\n",
    "    if _input_shape == None:\n",
    "        raise Exception('add input shape dim')\n",
    "    phos_input = layers.Input(shape=(_input_shape, 1))\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts', 8, 32, 8), kernel_size=16, \n",
    "        activation='relu')(phos_input)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts',8, 32, 8), kernel_size=8, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    drug_input = layers.Input(shape = (xdrug_train.shape[1]))\n",
    "    concatenated = layers.concatenate([x, drug_input])\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(concatenated)\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(hidd)\n",
    "    output_tensor = layers.Dense(1)(hidd)\n",
    "    model = tf.keras.Model([phos_input,drug_input], output_tensor)\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=hp.Choice('lr', [1e-4, 1e-3, 1e-2]))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.metrics.mean_squared_error, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cls in sets, relative to all clsbefore mising values are removed\n",
      "train fraction 0.7993158494868872, test fraction 0.10034207525655645,validaiton fraciton 0.10034207525655645\n",
      "------\n",
      "Fraction of cls in sets, relative to all cl drug pairs, aftermising values are removed\n",
      "train fraction 0.6972253895857089, test fraction0.08817939946788293, validaiton fraciton 0.0850693239469205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     2,      3,      4,      5,      6,      8,     10,     13,\n",
       "           16,     20,     26,     33,     42,     53,     67,     85,\n",
       "          108,    136,    173,    219,    277,    350,    443,    560,\n",
       "          708,    896,   1133,   1433,   1813,   2293,   2900,   3668,\n",
       "         4638,   5866,   7419,   9383,  11867,  15008,  18980,  24004,\n",
       "        26680,  30358,  38393,  48555,  61407,  77660,  98216, 124212,\n",
       "       157089, 198668])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to get train size\n",
    "rand_seed = 1\n",
    "pairs_with_truth_vals =  y_list.index\n",
    "train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "    rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals)\n",
    "\n",
    "\n",
    "#set train size search space. \n",
    "lg_space = np.logspace(1, 17.6, base=2.0).astype(int)\n",
    "lg_space = np.append(lg_space, len(test_pairs))\n",
    "lg_space = np.unique(lg_space)\n",
    "lg_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 06s]\n",
      "val_loss: 6.717092990875244\n",
      "\n",
      "Best val_loss So Far: 6.717092990875244\n",
      "Total elapsed time: 00h 00m 12s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "filts             |8                 |32                \n",
      "units             |192               |192               \n",
      "units_hid         |128               |160               \n",
      "lr                |0.001             |0.01              \n",
      "\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 22.8601 - mae: 4.4802 - val_loss: 46.8660 - val_mae: 6.3374\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 41.5906 - mae: 5.9012 - val_loss: 11.1734 - val_mae: 2.8967\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 13.0587 - mae: 3.2197 - val_loss: 8.2008 - val_mae: 2.1015\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 7.3791 - mae: 1.7758 - val_loss: 7.2198 - val_mae: 2.1871\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9252 - mae: 2.2941"
     ]
    }
   ],
   "source": [
    "#RNA\n",
    "#finds a test train split then finds the learning curve\n",
    "#for that split. Repeats for mutiple (N) test train splits \n",
    "N = 30\n",
    "\n",
    "for run in range(25, N):\n",
    "    print(f'run {run} of {N}')\n",
    "    #test train split\n",
    "    rand_seed = 42 + run\n",
    "    pairs_with_truth_vals =  y_list.index\n",
    "    train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "        rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals)\n",
    "\n",
    "    #rna test train selection\n",
    "    x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "    x_val_rna = x_all.loc[val_pairs]\n",
    "    y_train, y_test = y_list[train_pairs], y_list[test_pairs]\n",
    "    y_val = y_list[val_pairs]\n",
    "    xdrug_train, xdrug_test = x_drug.loc[train_pairs], x_drug.loc[test_pairs]\n",
    "    xdrug_val = x_drug.loc[val_pairs]\n",
    "\n",
    "    #prot test train selection\n",
    "    x_train_prot, x_test_prot = x_all_prot.loc[train_pairs], x_all_prot.loc[test_pairs]\n",
    "    x_val_prot = x_all_prot.loc[val_pairs]\n",
    "\n",
    "    #one hot test train seleciton\n",
    "    x_train_hot, x_test_hot = x_hot.loc[train_pairs], x_hot.loc[test_pairs]\n",
    "    x_val_hot = x_hot.loc[val_pairs]\n",
    "\n",
    "\n",
    "    #consistencey checks\n",
    "    assert (x_train_hot.index == x_train_rna.index).all()\n",
    "    assert (x_test_hot.index == x_test_rna.index).all()\n",
    "    assert (x_val_hot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (x_train_prot.index == x_train_rna.index).all()\n",
    "    assert (x_test_prot.index == x_test_rna.index).all()\n",
    "    assert (x_val_prot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (y_train.index == x_train_rna.index).all()\n",
    "    assert (y_test.index == x_test_rna.index).all()\n",
    "    assert (xdrug_test.index == x_test_rna.index).all()\n",
    "\n",
    "    #inconsistencey checks\n",
    "    assert x_train_rna.shape[1] != x_train_prot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_prot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_prot.shape[1]\n",
    "\n",
    "    assert x_train_rna.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_hot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_hot.shape[1]\n",
    "\n",
    "    assert x_train_prot.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_prot.shape[1] != x_test_hot.shape[1]\n",
    "\n",
    "    #run the learning curve\n",
    "    _input_shape = x_train_rna.shape[1]\n",
    "    mse_r2_rna, bms, bhps = lc_nb.run_lc_ucl(\n",
    "        build_cnn_kt,\n",
    "        [x_train_rna, xdrug_train], \n",
    "        y_train, \n",
    "        [x_val_rna, xdrug_val], \n",
    "        y_val, \n",
    "        [x_test_rna, xdrug_test],\n",
    "        y_test, \n",
    "        lg_space, \n",
    "        num_trails=15,\n",
    "        epochs=100,\n",
    "        direc='UCL-del1')\n",
    "    \n",
    "    #save data\n",
    "    mse_r2_rna.to_csv(f'LC-metric-results/RNA/run{run}')\n",
    "    bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "    bhps_df.to_csv(f'Optimal-hyperparameters/RNA/run{run}df')\n",
    "    with open(f'Optimal-hyperparameters/RNA/run{run}.pkl', 'wb') as f:\n",
    "        pickle.dump(bhps, f)\n",
    "    model_path = f'optimal-models/RNA/run{run}/model_train_size_'\n",
    "    for train_size, model in zip(lg_space, bms):\n",
    "        model.save(model_path + str(train_size)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check loading in the HPs and create models form that\n",
    "a fair amount different from what I had before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_path = 'Optimal-hyperparameters/RNA/'\n",
    "tt_path = 'test_train_cls/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 5.2457 - mae: 1.7343 - val_loss: 2.8232 - val_mae: 1.2814\n",
      "Epoch 2/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.8727 - mae: 1.0090 - val_loss: 1.9114 - val_mae: 1.0338\n",
      "Epoch 3/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.5321 - mae: 0.9166 - val_loss: 1.7405 - val_mae: 0.9885\n",
      "Epoch 4/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.4755 - mae: 0.8969 - val_loss: 1.7218 - val_mae: 0.9762\n",
      "Epoch 5/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.4346 - mae: 0.8828 - val_loss: 1.7652 - val_mae: 0.9938\n",
      "Epoch 6/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.3886 - mae: 0.8669 - val_loss: 1.6819 - val_mae: 0.9693\n",
      "Epoch 7/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.3421 - mae: 0.8509 - val_loss: 1.6518 - val_mae: 0.9559\n",
      "Epoch 8/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.3065 - mae: 0.8372 - val_loss: 1.6655 - val_mae: 0.9606\n",
      "Epoch 9/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.2769 - mae: 0.8262 - val_loss: 1.6283 - val_mae: 0.9472\n",
      "Epoch 10/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.2532 - mae: 0.8177 - val_loss: 1.5774 - val_mae: 0.9331\n",
      "Epoch 11/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.2309 - mae: 0.8093 - val_loss: 1.6158 - val_mae: 0.9541\n",
      "Epoch 12/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.2101 - mae: 0.8012 - val_loss: 1.5719 - val_mae: 0.9358\n",
      "Epoch 13/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.1896 - mae: 0.7942 - val_loss: 1.5680 - val_mae: 0.9296\n",
      "Epoch 14/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.1691 - mae: 0.7867 - val_loss: 1.6310 - val_mae: 0.9604\n",
      "Epoch 15/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.1513 - mae: 0.7802 - val_loss: 1.5852 - val_mae: 0.9370\n",
      "Epoch 16/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.1318 - mae: 0.7734 - val_loss: 1.5631 - val_mae: 0.9284\n",
      "Epoch 17/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.1125 - mae: 0.7673 - val_loss: 1.5764 - val_mae: 0.9361\n",
      "Epoch 18/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.0939 - mae: 0.7604 - val_loss: 1.5574 - val_mae: 0.9278\n",
      "Epoch 19/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.0777 - mae: 0.7550 - val_loss: 1.5822 - val_mae: 0.9397\n",
      "Epoch 20/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.0596 - mae: 0.7483 - val_loss: 1.5334 - val_mae: 0.9232\n",
      "Epoch 21/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.0427 - mae: 0.7427 - val_loss: 1.5731 - val_mae: 0.9358\n",
      "Epoch 22/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.0280 - mae: 0.7370 - val_loss: 1.5768 - val_mae: 0.9434\n",
      "Epoch 23/100\n",
      "1640/1640 [==============================] - 9s 6ms/step - loss: 1.0114 - mae: 0.7313 - val_loss: 1.5397 - val_mae: 0.9281\n",
      "Epoch 24/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.9966 - mae: 0.7261 - val_loss: 1.6596 - val_mae: 0.9615\n",
      "Epoch 25/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.9823 - mae: 0.7208 - val_loss: 1.5733 - val_mae: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1640/1640 [==============================] - 11s 6ms/step - loss: 4.0560 - mae: 1.4841 - val_loss: 1.9843 - val_mae: 1.0529\n",
      "Epoch 2/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.5375 - mae: 0.9182 - val_loss: 1.7254 - val_mae: 0.9761\n",
      "Epoch 3/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.4282 - mae: 0.8825 - val_loss: 2.1023 - val_mae: 1.1083\n",
      "Epoch 4/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.3426 - mae: 0.8522 - val_loss: 1.6670 - val_mae: 0.9537\n",
      "Epoch 5/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.2810 - mae: 0.8294 - val_loss: 1.6510 - val_mae: 0.9483\n",
      "Epoch 6/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.2324 - mae: 0.8120 - val_loss: 1.6413 - val_mae: 0.9521\n",
      "Epoch 7/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.1918 - mae: 0.7969 - val_loss: 1.6832 - val_mae: 0.9620\n",
      "Epoch 8/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.1551 - mae: 0.7837 - val_loss: 1.6765 - val_mae: 0.9570\n",
      "Epoch 9/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.1219 - mae: 0.7716 - val_loss: 1.6795 - val_mae: 0.9603\n",
      "Epoch 10/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.0849 - mae: 0.7583 - val_loss: 1.6248 - val_mae: 0.9505\n",
      "Epoch 11/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.0534 - mae: 0.7476 - val_loss: 1.6156 - val_mae: 0.9406\n",
      "Epoch 12/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 1.0196 - mae: 0.7358 - val_loss: 1.6578 - val_mae: 0.9578\n",
      "Epoch 13/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.9883 - mae: 0.7241 - val_loss: 1.5732 - val_mae: 0.9304\n",
      "Epoch 14/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.9587 - mae: 0.7136 - val_loss: 1.6263 - val_mae: 0.9450\n",
      "Epoch 15/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.9288 - mae: 0.7031 - val_loss: 1.6413 - val_mae: 0.9433\n",
      "Epoch 16/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.9004 - mae: 0.6921 - val_loss: 1.6721 - val_mae: 0.9570\n",
      "Epoch 17/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.8733 - mae: 0.6820 - val_loss: 1.6466 - val_mae: 0.9534\n",
      "Epoch 18/100\n",
      "1640/1640 [==============================] - 10s 6ms/step - loss: 0.8477 - mae: 0.6726 - val_loss: 1.6563 - val_mae: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 2.0066 - mae: 1.0215 - val_loss: 1.5826 - val_mae: 0.9260\n",
      "Epoch 2/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.3319 - mae: 0.8464 - val_loss: 1.6629 - val_mae: 0.9437\n",
      "Epoch 3/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.2567 - mae: 0.8198 - val_loss: 1.5551 - val_mae: 0.9204\n",
      "Epoch 4/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.1924 - mae: 0.7967 - val_loss: 1.6049 - val_mae: 0.9380\n",
      "Epoch 5/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.1336 - mae: 0.7763 - val_loss: 1.5622 - val_mae: 0.9173\n",
      "Epoch 6/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.0852 - mae: 0.7590 - val_loss: 1.5902 - val_mae: 0.9282\n",
      "Epoch 7/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.0425 - mae: 0.7449 - val_loss: 1.5342 - val_mae: 0.9131\n",
      "Epoch 8/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 1.0077 - mae: 0.7316 - val_loss: 1.5532 - val_mae: 0.9171\n",
      "Epoch 9/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.9767 - mae: 0.7197 - val_loss: 1.5571 - val_mae: 0.9131\n",
      "Epoch 10/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.9522 - mae: 0.7108 - val_loss: 1.5932 - val_mae: 0.9296\n",
      "Epoch 11/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.9276 - mae: 0.7015 - val_loss: 1.5775 - val_mae: 0.9240\n",
      "Epoch 12/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.9074 - mae: 0.6940 - val_loss: 1.5328 - val_mae: 0.9138\n",
      "Epoch 13/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.8882 - mae: 0.6862 - val_loss: 1.6367 - val_mae: 0.9374\n",
      "Epoch 14/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.8712 - mae: 0.6799 - val_loss: 1.5779 - val_mae: 0.9172\n",
      "Epoch 15/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.8545 - mae: 0.6733 - val_loss: 1.5564 - val_mae: 0.9173\n",
      "Epoch 16/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.8410 - mae: 0.6681 - val_loss: 1.5776 - val_mae: 0.9230\n",
      "Epoch 17/100\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 0.8257 - mae: 0.6622 - val_loss: 1.5545 - val_mae: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 11s 6ms/step - loss: 4.2237 - mae: 1.5189 - val_loss: 2.0578 - val_mae: 1.0752\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.6454 - mae: 0.9510 - val_loss: 1.6618 - val_mae: 0.9562\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.5002 - mae: 0.9057 - val_loss: 1.6844 - val_mae: 0.9685\n",
      "Epoch 4/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.4247 - mae: 0.8811 - val_loss: 1.6133 - val_mae: 0.9441\n",
      "Epoch 5/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.3524 - mae: 0.8557 - val_loss: 1.5745 - val_mae: 0.9246\n",
      "Epoch 6/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.3054 - mae: 0.8389 - val_loss: 1.7043 - val_mae: 0.9704\n",
      "Epoch 7/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.2715 - mae: 0.8257 - val_loss: 1.6235 - val_mae: 0.9417\n",
      "Epoch 8/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.2429 - mae: 0.8153 - val_loss: 1.5143 - val_mae: 0.9052\n",
      "Epoch 9/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.2151 - mae: 0.8056 - val_loss: 1.5740 - val_mae: 0.9248\n",
      "Epoch 10/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1877 - mae: 0.7954 - val_loss: 1.5468 - val_mae: 0.9208\n",
      "Epoch 11/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1650 - mae: 0.7879 - val_loss: 1.5704 - val_mae: 0.9239\n",
      "Epoch 12/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1399 - mae: 0.7789 - val_loss: 1.5508 - val_mae: 0.9160\n",
      "Epoch 13/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1170 - mae: 0.7706 - val_loss: 1.5116 - val_mae: 0.9026\n",
      "Epoch 14/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0938 - mae: 0.7625 - val_loss: 1.5368 - val_mae: 0.9120\n",
      "Epoch 15/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0720 - mae: 0.7554 - val_loss: 1.5724 - val_mae: 0.9224\n",
      "Epoch 16/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0511 - mae: 0.7475 - val_loss: 1.5297 - val_mae: 0.9065\n",
      "Epoch 17/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0329 - mae: 0.7412 - val_loss: 1.5688 - val_mae: 0.9232\n",
      "Epoch 18/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0136 - mae: 0.7340 - val_loss: 1.5392 - val_mae: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 11s 6ms/step - loss: 2.3594 - mae: 1.0712 - val_loss: 1.7316 - val_mae: 0.9802\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.3474 - mae: 0.8516 - val_loss: 1.7056 - val_mae: 0.9741\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.2555 - mae: 0.8200 - val_loss: 1.6878 - val_mae: 0.9663\n",
      "Epoch 4/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1768 - mae: 0.7925 - val_loss: 1.7083 - val_mae: 0.9682\n",
      "Epoch 5/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1053 - mae: 0.7677 - val_loss: 1.6901 - val_mae: 0.9638\n",
      "Epoch 6/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0482 - mae: 0.7474 - val_loss: 1.7085 - val_mae: 0.9649\n",
      "Epoch 7/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0032 - mae: 0.7303 - val_loss: 1.7305 - val_mae: 0.9742\n",
      "Epoch 8/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.9602 - mae: 0.7150 - val_loss: 1.6875 - val_mae: 0.9614\n",
      "Epoch 9/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.9271 - mae: 0.7014 - val_loss: 1.6749 - val_mae: 0.9645\n",
      "Epoch 10/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.8971 - mae: 0.6907 - val_loss: 1.6559 - val_mae: 0.9452\n",
      "Epoch 11/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.8670 - mae: 0.6786 - val_loss: 1.7285 - val_mae: 0.9683\n",
      "Epoch 12/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.8416 - mae: 0.6685 - val_loss: 1.7414 - val_mae: 0.9732\n",
      "Epoch 13/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.8165 - mae: 0.6585 - val_loss: 1.6874 - val_mae: 0.9642\n",
      "Epoch 14/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.7957 - mae: 0.6503 - val_loss: 1.7080 - val_mae: 0.9684\n",
      "Epoch 15/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.7782 - mae: 0.6432 - val_loss: 1.6621 - val_mae: 0.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 2.5487 - mae: 1.1324 - val_loss: 1.6084 - val_mae: 0.9333\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.3275 - mae: 0.8451 - val_loss: 1.5812 - val_mae: 0.9290\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.2536 - mae: 0.8193 - val_loss: 1.5939 - val_mae: 0.9236\n",
      "Epoch 4/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1864 - mae: 0.7956 - val_loss: 1.4841 - val_mae: 0.8990\n",
      "Epoch 5/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.1346 - mae: 0.7772 - val_loss: 1.5146 - val_mae: 0.9052\n",
      "Epoch 6/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0869 - mae: 0.7600 - val_loss: 1.5413 - val_mae: 0.9224\n",
      "Epoch 7/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0474 - mae: 0.7459 - val_loss: 1.4992 - val_mae: 0.8983\n",
      "Epoch 8/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 1.0123 - mae: 0.7327 - val_loss: 1.5819 - val_mae: 0.9260\n",
      "Epoch 9/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 0.9820 - mae: 0.7219 - val_loss: 1.5006 - val_mae: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 6.1102 - mae: 1.9057 - val_loss: 5.1477 - val_mae: 1.6444\n",
      "Epoch 2/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 2.8749 - mae: 1.2442 - val_loss: 1.8580 - val_mae: 1.0099\n",
      "Epoch 3/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.6314 - mae: 0.9452 - val_loss: 1.6465 - val_mae: 0.9555\n",
      "Epoch 4/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.5155 - mae: 0.9106 - val_loss: 1.6072 - val_mae: 0.9441\n",
      "Epoch 5/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.4770 - mae: 0.8970 - val_loss: 1.5879 - val_mae: 0.9414\n",
      "Epoch 6/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.4427 - mae: 0.8851 - val_loss: 1.6847 - val_mae: 0.9680\n",
      "Epoch 7/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.4042 - mae: 0.8713 - val_loss: 1.6725 - val_mae: 0.9654\n",
      "Epoch 8/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.3646 - mae: 0.8572 - val_loss: 1.5098 - val_mae: 0.9130\n",
      "Epoch 9/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.3315 - mae: 0.8457 - val_loss: 1.4894 - val_mae: 0.9088\n",
      "Epoch 10/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.3042 - mae: 0.8357 - val_loss: 1.4796 - val_mae: 0.9018\n",
      "Epoch 11/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.2825 - mae: 0.8282 - val_loss: 1.4842 - val_mae: 0.9089\n",
      "Epoch 12/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.2661 - mae: 0.8220 - val_loss: 1.4772 - val_mae: 0.9042\n",
      "Epoch 13/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.2491 - mae: 0.8162 - val_loss: 1.4498 - val_mae: 0.8953\n",
      "Epoch 14/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.2334 - mae: 0.8104 - val_loss: 1.4906 - val_mae: 0.9086\n",
      "Epoch 15/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.2187 - mae: 0.8053 - val_loss: 1.4400 - val_mae: 0.8911\n",
      "Epoch 16/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.2032 - mae: 0.7995 - val_loss: 1.4597 - val_mae: 0.8931\n",
      "Epoch 17/100\n",
      "1642/1642 [==============================] - 9s 6ms/step - loss: 1.1875 - mae: 0.7943 - val_loss: 1.4594 - val_mae: 0.8941\n",
      "Epoch 18/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.1737 - mae: 0.7892 - val_loss: 1.4697 - val_mae: 0.9006\n",
      "Epoch 19/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.1591 - mae: 0.7841 - val_loss: 1.4689 - val_mae: 0.9036\n",
      "Epoch 20/100\n",
      "1642/1642 [==============================] - 10s 6ms/step - loss: 1.1453 - mae: 0.7792 - val_loss: 1.5020 - val_mae: 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 4.1648 - mae: 1.5095 - val_loss: 2.4131 - val_mae: 1.1780\n",
      "Epoch 2/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.5905 - mae: 0.9359 - val_loss: 1.9557 - val_mae: 1.0424\n",
      "Epoch 3/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.4609 - mae: 0.8945 - val_loss: 1.8320 - val_mae: 0.9899\n",
      "Epoch 4/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.3995 - mae: 0.8741 - val_loss: 1.8073 - val_mae: 0.9889\n",
      "Epoch 5/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.3369 - mae: 0.8529 - val_loss: 1.7191 - val_mae: 0.9586\n",
      "Epoch 6/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.2916 - mae: 0.8364 - val_loss: 1.7203 - val_mae: 0.9557\n",
      "Epoch 7/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.2571 - mae: 0.8238 - val_loss: 1.7307 - val_mae: 0.9623\n",
      "Epoch 8/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.2279 - mae: 0.8124 - val_loss: 1.7142 - val_mae: 0.9579\n",
      "Epoch 9/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.2007 - mae: 0.8022 - val_loss: 1.6879 - val_mae: 0.9471\n",
      "Epoch 10/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.1749 - mae: 0.7926 - val_loss: 1.7215 - val_mae: 0.9550\n",
      "Epoch 11/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.1516 - mae: 0.7837 - val_loss: 1.6982 - val_mae: 0.9507\n",
      "Epoch 12/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.1272 - mae: 0.7754 - val_loss: 1.6663 - val_mae: 0.9419\n",
      "Epoch 13/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.1018 - mae: 0.7662 - val_loss: 1.6986 - val_mae: 0.9537\n",
      "Epoch 14/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.0779 - mae: 0.7577 - val_loss: 1.6821 - val_mae: 0.9502\n",
      "Epoch 15/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.0531 - mae: 0.7490 - val_loss: 1.7020 - val_mae: 0.9634\n",
      "Epoch 16/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.0306 - mae: 0.7411 - val_loss: 1.6764 - val_mae: 0.9511\n",
      "Epoch 17/100\n",
      "1648/1648 [==============================] - 10s 6ms/step - loss: 1.0091 - mae: 0.7335 - val_loss: 1.7732 - val_mae: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 3.9295 - mae: 1.4571 - val_loss: 1.8795 - val_mae: 1.0156\n",
      "Epoch 2/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.5703 - mae: 0.9285 - val_loss: 2.0101 - val_mae: 1.0813\n",
      "Epoch 3/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.4617 - mae: 0.8947 - val_loss: 1.7793 - val_mae: 0.9951\n",
      "Epoch 4/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.3838 - mae: 0.8671 - val_loss: 1.6238 - val_mae: 0.9446\n",
      "Epoch 5/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.3210 - mae: 0.8454 - val_loss: 1.6008 - val_mae: 0.9318\n",
      "Epoch 6/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.2784 - mae: 0.8297 - val_loss: 1.6056 - val_mae: 0.9381\n",
      "Epoch 7/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.2464 - mae: 0.8177 - val_loss: 1.6326 - val_mae: 0.9419\n",
      "Epoch 8/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.2186 - mae: 0.8075 - val_loss: 1.6200 - val_mae: 0.9451\n",
      "Epoch 9/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.1938 - mae: 0.7982 - val_loss: 1.5905 - val_mae: 0.9293\n",
      "Epoch 10/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.1694 - mae: 0.7898 - val_loss: 1.6211 - val_mae: 0.9525\n",
      "Epoch 11/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.1481 - mae: 0.7814 - val_loss: 1.5823 - val_mae: 0.9260\n",
      "Epoch 12/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.1262 - mae: 0.7737 - val_loss: 1.5743 - val_mae: 0.9212\n",
      "Epoch 13/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.1024 - mae: 0.7650 - val_loss: 1.5883 - val_mae: 0.9265\n",
      "Epoch 14/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.0810 - mae: 0.7571 - val_loss: 1.5858 - val_mae: 0.9283\n",
      "Epoch 15/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.0586 - mae: 0.7499 - val_loss: 1.5978 - val_mae: 0.9307\n",
      "Epoch 16/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.0367 - mae: 0.7421 - val_loss: 1.5715 - val_mae: 0.9242\n",
      "Epoch 17/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 1.0147 - mae: 0.7345 - val_loss: 1.6006 - val_mae: 0.9342\n",
      "Epoch 18/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.9938 - mae: 0.7271 - val_loss: 1.5845 - val_mae: 0.9301\n",
      "Epoch 19/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.9741 - mae: 0.7207 - val_loss: 1.6327 - val_mae: 0.9437\n",
      "Epoch 20/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.9543 - mae: 0.7132 - val_loss: 1.5849 - val_mae: 0.9310\n",
      "Epoch 21/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.9353 - mae: 0.7065 - val_loss: 1.5580 - val_mae: 0.9227\n",
      "Epoch 22/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.9174 - mae: 0.7001 - val_loss: 1.5486 - val_mae: 0.9160\n",
      "Epoch 23/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.9010 - mae: 0.6936 - val_loss: 1.5683 - val_mae: 0.9234\n",
      "Epoch 24/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.8850 - mae: 0.6879 - val_loss: 1.5900 - val_mae: 0.9284\n",
      "Epoch 25/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.8709 - mae: 0.6829 - val_loss: 1.5525 - val_mae: 0.9193\n",
      "Epoch 26/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.8570 - mae: 0.6771 - val_loss: 1.6186 - val_mae: 0.9418\n",
      "Epoch 27/100\n",
      "1638/1638 [==============================] - 10s 6ms/step - loss: 0.8435 - mae: 0.6723 - val_loss: 1.5846 - val_mae: 0.9271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wpw035/.conda/envs/tfGPUforge/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1651/1651 [==============================] - 11s 6ms/step - loss: 2.3484 - mae: 1.0958 - val_loss: 1.7588 - val_mae: 0.9843\n",
      "Epoch 2/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.3214 - mae: 0.8455 - val_loss: 1.6869 - val_mae: 0.9606\n",
      "Epoch 3/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.2540 - mae: 0.8201 - val_loss: 1.7494 - val_mae: 0.9822\n",
      "Epoch 4/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.2046 - mae: 0.8022 - val_loss: 1.7646 - val_mae: 0.9920\n",
      "Epoch 5/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.1569 - mae: 0.7853 - val_loss: 1.7278 - val_mae: 0.9672\n",
      "Epoch 6/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.1156 - mae: 0.7711 - val_loss: 1.7007 - val_mae: 0.9593\n",
      "Epoch 7/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.0749 - mae: 0.7562 - val_loss: 1.6833 - val_mae: 0.9540\n",
      "Epoch 8/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.0369 - mae: 0.7433 - val_loss: 1.7308 - val_mae: 0.9749\n",
      "Epoch 9/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 1.0075 - mae: 0.7322 - val_loss: 1.7142 - val_mae: 0.9603\n",
      "Epoch 10/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 0.9804 - mae: 0.7218 - val_loss: 1.6963 - val_mae: 0.9629\n",
      "Epoch 11/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 0.9551 - mae: 0.7124 - val_loss: 1.7188 - val_mae: 0.9708\n",
      "Epoch 12/100\n",
      "1651/1651 [==============================] - 10s 6ms/step - loss: 0.9364 - mae: 0.7063 - val_loss: 1.7183 - val_mae: 0.9690\n"
     ]
    }
   ],
   "source": [
    "test_results = {'r2': [], 'mse': [], 'rho' : []}\n",
    "_input_shape = x_all.shape[1]\n",
    "for run in range(0, 10):\n",
    "\n",
    "    train_pairs = pd.read_csv(f'{tt_path}train_pairs{run}', dtype=str, \n",
    "                          delimiter='/n',header=None)\n",
    "    test_pairs = pd.read_csv(f'{tt_path}test_pairs{run}', dtype=str, \n",
    "                          delimiter='/n',header=None)\n",
    "    val_pairs = pd.read_csv(f'{tt_path}val_pairs{run}', dtype=str, \n",
    "                          delimiter='/n',header=None)\n",
    "    train_pairs = train_pairs[0].values\n",
    "    test_pairs = test_pairs[0].values\n",
    "    val_pairs  = val_pairs[0].values\n",
    "\n",
    "    #rna test train selection\n",
    "    x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "    x_val_rna = x_all.loc[val_pairs]\n",
    "    y_train, y_test = y_list[train_pairs], y_list[test_pairs]\n",
    "    y_val = y_list[val_pairs]\n",
    "    xdrug_train, xdrug_test = x_drug.loc[train_pairs], x_drug.loc[test_pairs]\n",
    "    xdrug_val = x_drug.loc[val_pairs]\n",
    "\n",
    "    #create and fit model with final data size.\n",
    "    f = open(f'{hp_path}run{run}.pkl', 'rb')\n",
    "    hp_load = pickle.load(f)\n",
    "    f.close()\n",
    "    model = build_cnn_kt(hp_load[-1])\n",
    "\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5, \n",
    "                               restore_best_weights=True)]\n",
    "\n",
    "\n",
    "\n",
    "    model.fit([x_train_rna, xdrug_train], y_train,\n",
    "              validation_data=([x_val_rna, xdrug_val], y_val),\n",
    "              epochs=100,\n",
    "              callbacks=callbacks,\n",
    "              batch_size=128\n",
    "        )\n",
    "\n",
    "    #make predctions using the opt model\n",
    "    pre = model.predict([x_test_rna, xdrug_test])\n",
    "    pre = pre.reshape(len(pre))\n",
    "    test_results['rho'].append(scipy.stats.pearsonr(y_test, pre))\n",
    "    test_results['r2'].append(sklearn.metrics.r2_score(y_test, pre))\n",
    "    test_results['mse'].append(sklearn.metrics.mean_squared_error(y_test, pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779061</td>\n",
       "      <td>1.522273</td>\n",
       "      <td>(0.8844822228301752, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.774705</td>\n",
       "      <td>1.547763</td>\n",
       "      <td>(0.8832897093048311, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781551</td>\n",
       "      <td>1.477086</td>\n",
       "      <td>(0.8842145179154487, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.752757</td>\n",
       "      <td>1.660370</td>\n",
       "      <td>(0.8690738868844304, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777163</td>\n",
       "      <td>1.519671</td>\n",
       "      <td>(0.8818154292117533, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.737942</td>\n",
       "      <td>1.742636</td>\n",
       "      <td>(0.8604518080052003, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.764542</td>\n",
       "      <td>1.576318</td>\n",
       "      <td>(0.8744653539259567, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.758026</td>\n",
       "      <td>1.645188</td>\n",
       "      <td>(0.8713530159070254, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.736138</td>\n",
       "      <td>1.785626</td>\n",
       "      <td>(0.858839100628207, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.758610</td>\n",
       "      <td>1.669756</td>\n",
       "      <td>(0.8713034845954499, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         r2       mse                        rho\n",
       "0  0.779061  1.522273  (0.8844822228301752, 0.0)\n",
       "1  0.774705  1.547763  (0.8832897093048311, 0.0)\n",
       "2  0.781551  1.477086  (0.8842145179154487, 0.0)\n",
       "3  0.752757  1.660370  (0.8690738868844304, 0.0)\n",
       "4  0.777163  1.519671  (0.8818154292117533, 0.0)\n",
       "5  0.737942  1.742636  (0.8604518080052003, 0.0)\n",
       "6  0.764542  1.576318  (0.8744653539259567, 0.0)\n",
       "7  0.758026  1.645188  (0.8713530159070254, 0.0)\n",
       "8  0.736138  1.785626   (0.858839100628207, 0.0)\n",
       "9  0.758610  1.669756  (0.8713034845954499, 0.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782423</td>\n",
       "      <td>1.499113</td>\n",
       "      <td>(0.8851309570895478, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768829</td>\n",
       "      <td>1.588129</td>\n",
       "      <td>(0.877253198022631, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.787669</td>\n",
       "      <td>1.435717</td>\n",
       "      <td>(0.8876906255774633, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.755087</td>\n",
       "      <td>1.644722</td>\n",
       "      <td>(0.8702065076396063, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786594</td>\n",
       "      <td>1.455355</td>\n",
       "      <td>(0.8872465961928492, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.736280</td>\n",
       "      <td>1.753687</td>\n",
       "      <td>(0.8612760326017215, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.770250</td>\n",
       "      <td>1.538103</td>\n",
       "      <td>(0.8779800249678034, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756510</td>\n",
       "      <td>1.655495</td>\n",
       "      <td>(0.870798518432726, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739969</td>\n",
       "      <td>1.759703</td>\n",
       "      <td>(0.861194891052643, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.762738</td>\n",
       "      <td>1.641199</td>\n",
       "      <td>(0.8742154490725469, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         r2       mse                        rho\n",
       "0  0.782423  1.499113  (0.8851309570895478, 0.0)\n",
       "1  0.768829  1.588129   (0.877253198022631, 0.0)\n",
       "2  0.787669  1.435717  (0.8876906255774633, 0.0)\n",
       "3  0.755087  1.644722  (0.8702065076396063, 0.0)\n",
       "4  0.786594  1.455355  (0.8872465961928492, 0.0)\n",
       "5  0.736280  1.753687  (0.8612760326017215, 0.0)\n",
       "6  0.770250  1.538103  (0.8779800249678034, 0.0)\n",
       "7  0.756510  1.655495   (0.870798518432726, 0.0)\n",
       "8  0.739969  1.759703   (0.861194891052643, 0.0)\n",
       "9  0.762738  1.641199  (0.8742154490725469, 0.0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(import_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import_results = {'r2': [], 'mse': [], 'rho' : []}\n",
    "\n",
    "for run in range(0, 10):\n",
    "    imp = pd.read_csv(f'LC-metric-results/RNA/run{run}').iloc[-1]\n",
    "    import_results['r2'].append(imp['r2'])\n",
    "    import_results['mse'].append(imp['mse'])\n",
    "    import_results['rho'].append(imp['rho'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>rho</th>\n",
       "      <th>train size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>6.938752</td>\n",
       "      <td>(0.01634634781390522, 0.00785402067895004)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.006600</td>\n",
       "      <td>6.935496</td>\n",
       "      <td>(0.05700137924380597, 1.749363358036882e-20)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>6.935248</td>\n",
       "      <td>(0.13720963580815163, 2.62944867484629e-111)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.003861</td>\n",
       "      <td>6.916628</td>\n",
       "      <td>(0.06776613293108544, 2.6714148099086835e-28)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>6.900357</td>\n",
       "      <td>(0.059410176552587735, 4.070782066799802e-22)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.003166</td>\n",
       "      <td>6.911840</td>\n",
       "      <td>(0.06232432691891631, 3.5051639565363745e-24)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>6.859362</td>\n",
       "      <td>(0.11308099547545845, 5.464882570654515e-76)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>6.882057</td>\n",
       "      <td>(0.10197538093186086, 4.5384869524186375e-62)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>6.884090</td>\n",
       "      <td>(0.11681767966359655, 5.305624831804361e-81)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>6.883018</td>\n",
       "      <td>(0.09825395222424599, 9.882753041289182e-58)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>6.926752</td>\n",
       "      <td>(0.06607226515070733, 5.561041984143209e-27)</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>6.934089</td>\n",
       "      <td>(0.10600905810156153, 5.8920739633633894e-67)</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>6.855752</td>\n",
       "      <td>(0.14423652171062085, 6.497359021341145e-123)</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.034473</td>\n",
       "      <td>6.652502</td>\n",
       "      <td>(0.19772978704302682, 2.4635205196506344e-231)</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.074012</td>\n",
       "      <td>6.380077</td>\n",
       "      <td>(0.27823132753841373, 0.0)</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>6.846460</td>\n",
       "      <td>(0.191951540949383, 6.980745607858157e-218)</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>6.508683</td>\n",
       "      <td>(0.3436441954892646, 0.0)</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>6.529770</td>\n",
       "      <td>(0.31573435145687867, 0.0)</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.225065</td>\n",
       "      <td>5.339318</td>\n",
       "      <td>(0.4893769536931735, 0.0)</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.261153</td>\n",
       "      <td>5.090675</td>\n",
       "      <td>(0.5278841755646674, 0.0)</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>4.989958</td>\n",
       "      <td>(0.5486183034128904, 0.0)</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.331615</td>\n",
       "      <td>4.605191</td>\n",
       "      <td>(0.5806668394861001, 0.0)</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.417996</td>\n",
       "      <td>4.010023</td>\n",
       "      <td>(0.6494169625642845, 0.0)</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.452602</td>\n",
       "      <td>3.771585</td>\n",
       "      <td>(0.6854047052673575, 0.0)</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.543935</td>\n",
       "      <td>3.142299</td>\n",
       "      <td>(0.7404619687958635, 0.0)</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.594576</td>\n",
       "      <td>2.793379</td>\n",
       "      <td>(0.7740817816228768, 0.0)</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.631408</td>\n",
       "      <td>2.539610</td>\n",
       "      <td>(0.7946473067558958, 0.0)</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.657375</td>\n",
       "      <td>2.360697</td>\n",
       "      <td>(0.8158695098532576, 0.0)</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.667627</td>\n",
       "      <td>2.290060</td>\n",
       "      <td>(0.8190472749859914, 0.0)</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.706931</td>\n",
       "      <td>2.019249</td>\n",
       "      <td>(0.8448795541925764, 0.0)</td>\n",
       "      <td>2293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.716416</td>\n",
       "      <td>1.953902</td>\n",
       "      <td>(0.8466801405339143, 0.0)</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.731224</td>\n",
       "      <td>1.851870</td>\n",
       "      <td>(0.8566612698235336, 0.0)</td>\n",
       "      <td>3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.729925</td>\n",
       "      <td>1.860826</td>\n",
       "      <td>(0.8586151352353196, 0.0)</td>\n",
       "      <td>4638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.756124</td>\n",
       "      <td>1.680313</td>\n",
       "      <td>(0.8696411644925464, 0.0)</td>\n",
       "      <td>5866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.758326</td>\n",
       "      <td>1.665138</td>\n",
       "      <td>(0.871340692248747, 0.0)</td>\n",
       "      <td>7419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.757169</td>\n",
       "      <td>1.673112</td>\n",
       "      <td>(0.8705946325640859, 0.0)</td>\n",
       "      <td>9383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.754438</td>\n",
       "      <td>1.691931</td>\n",
       "      <td>(0.8699238284412492, 0.0)</td>\n",
       "      <td>11867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.769504</td>\n",
       "      <td>1.588125</td>\n",
       "      <td>(0.8784090054085895, 0.0)</td>\n",
       "      <td>15008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.761950</td>\n",
       "      <td>1.640173</td>\n",
       "      <td>(0.8730414174031381, 0.0)</td>\n",
       "      <td>18980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.762280</td>\n",
       "      <td>1.637897</td>\n",
       "      <td>(0.8732637126419409, 0.0)</td>\n",
       "      <td>24004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.768222</td>\n",
       "      <td>1.596959</td>\n",
       "      <td>(0.8794094010170328, 0.0)</td>\n",
       "      <td>30358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.771801</td>\n",
       "      <td>1.572299</td>\n",
       "      <td>(0.8800273035855573, 0.0)</td>\n",
       "      <td>38393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.782978</td>\n",
       "      <td>1.495286</td>\n",
       "      <td>(0.8849452356010143, 0.0)</td>\n",
       "      <td>48555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.785400</td>\n",
       "      <td>1.478599</td>\n",
       "      <td>(0.8866827324602018, 0.0)</td>\n",
       "      <td>61407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.775911</td>\n",
       "      <td>1.543979</td>\n",
       "      <td>(0.8809206579017885, 0.0)</td>\n",
       "      <td>77660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.776069</td>\n",
       "      <td>1.542888</td>\n",
       "      <td>(0.8810319181471701, 0.0)</td>\n",
       "      <td>98216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.786798</td>\n",
       "      <td>1.468965</td>\n",
       "      <td>(0.8874471529935656, 0.0)</td>\n",
       "      <td>124212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.781695</td>\n",
       "      <td>1.504127</td>\n",
       "      <td>(0.884264805946993, 0.0)</td>\n",
       "      <td>157089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.769712</td>\n",
       "      <td>1.586688</td>\n",
       "      <td>(0.8819350314953858, 0.0)</td>\n",
       "      <td>198668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.782423</td>\n",
       "      <td>1.499113</td>\n",
       "      <td>(0.8851309570895478, 0.0)</td>\n",
       "      <td>209846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        r2       mse  \\\n",
       "0            0 -0.007072  6.938752   \n",
       "1            1 -0.006600  6.935496   \n",
       "2            2 -0.006564  6.935248   \n",
       "3            3 -0.003861  6.916628   \n",
       "4            4 -0.001500  6.900357   \n",
       "5            5 -0.003166  6.911840   \n",
       "6            6  0.004450  6.859362   \n",
       "7            7  0.001156  6.882057   \n",
       "8            8  0.000861  6.884090   \n",
       "9            9  0.001017  6.883018   \n",
       "10          10 -0.005331  6.926752   \n",
       "11          11 -0.006396  6.934089   \n",
       "12          12  0.004974  6.855752   \n",
       "13          13  0.034473  6.652502   \n",
       "14          14  0.074012  6.380077   \n",
       "15          15  0.006323  6.846460   \n",
       "16          16  0.055347  6.508683   \n",
       "17          17  0.052286  6.529770   \n",
       "18          18  0.225065  5.339318   \n",
       "19          19  0.261153  5.090675   \n",
       "20          20  0.275770  4.989958   \n",
       "21          21  0.331615  4.605191   \n",
       "22          22  0.417996  4.010023   \n",
       "23          23  0.452602  3.771585   \n",
       "24          24  0.543935  3.142299   \n",
       "25          25  0.594576  2.793379   \n",
       "26          26  0.631408  2.539610   \n",
       "27          27  0.657375  2.360697   \n",
       "28          28  0.667627  2.290060   \n",
       "29          29  0.706931  2.019249   \n",
       "30          30  0.716416  1.953902   \n",
       "31          31  0.731224  1.851870   \n",
       "32          32  0.729925  1.860826   \n",
       "33          33  0.756124  1.680313   \n",
       "34          34  0.758326  1.665138   \n",
       "35          35  0.757169  1.673112   \n",
       "36          36  0.754438  1.691931   \n",
       "37          37  0.769504  1.588125   \n",
       "38          38  0.761950  1.640173   \n",
       "39          39  0.762280  1.637897   \n",
       "40          40  0.768222  1.596959   \n",
       "41          41  0.771801  1.572299   \n",
       "42          42  0.782978  1.495286   \n",
       "43          43  0.785400  1.478599   \n",
       "44          44  0.775911  1.543979   \n",
       "45          45  0.776069  1.542888   \n",
       "46          46  0.786798  1.468965   \n",
       "47          47  0.781695  1.504127   \n",
       "48          48  0.769712  1.586688   \n",
       "49          49  0.782423  1.499113   \n",
       "\n",
       "                                               rho  train size  \n",
       "0       (0.01634634781390522, 0.00785402067895004)           2  \n",
       "1     (0.05700137924380597, 1.749363358036882e-20)           3  \n",
       "2     (0.13720963580815163, 2.62944867484629e-111)           4  \n",
       "3    (0.06776613293108544, 2.6714148099086835e-28)           5  \n",
       "4    (0.059410176552587735, 4.070782066799802e-22)           6  \n",
       "5    (0.06232432691891631, 3.5051639565363745e-24)           8  \n",
       "6     (0.11308099547545845, 5.464882570654515e-76)          10  \n",
       "7    (0.10197538093186086, 4.5384869524186375e-62)          13  \n",
       "8     (0.11681767966359655, 5.305624831804361e-81)          16  \n",
       "9     (0.09825395222424599, 9.882753041289182e-58)          20  \n",
       "10    (0.06607226515070733, 5.561041984143209e-27)          26  \n",
       "11   (0.10600905810156153, 5.8920739633633894e-67)          33  \n",
       "12   (0.14423652171062085, 6.497359021341145e-123)          42  \n",
       "13  (0.19772978704302682, 2.4635205196506344e-231)          53  \n",
       "14                      (0.27823132753841373, 0.0)          67  \n",
       "15     (0.191951540949383, 6.980745607858157e-218)          85  \n",
       "16                       (0.3436441954892646, 0.0)         108  \n",
       "17                      (0.31573435145687867, 0.0)         136  \n",
       "18                       (0.4893769536931735, 0.0)         173  \n",
       "19                       (0.5278841755646674, 0.0)         219  \n",
       "20                       (0.5486183034128904, 0.0)         277  \n",
       "21                       (0.5806668394861001, 0.0)         350  \n",
       "22                       (0.6494169625642845, 0.0)         443  \n",
       "23                       (0.6854047052673575, 0.0)         560  \n",
       "24                       (0.7404619687958635, 0.0)         708  \n",
       "25                       (0.7740817816228768, 0.0)         896  \n",
       "26                       (0.7946473067558958, 0.0)        1133  \n",
       "27                       (0.8158695098532576, 0.0)        1433  \n",
       "28                       (0.8190472749859914, 0.0)        1813  \n",
       "29                       (0.8448795541925764, 0.0)        2293  \n",
       "30                       (0.8466801405339143, 0.0)        2900  \n",
       "31                       (0.8566612698235336, 0.0)        3668  \n",
       "32                       (0.8586151352353196, 0.0)        4638  \n",
       "33                       (0.8696411644925464, 0.0)        5866  \n",
       "34                        (0.871340692248747, 0.0)        7419  \n",
       "35                       (0.8705946325640859, 0.0)        9383  \n",
       "36                       (0.8699238284412492, 0.0)       11867  \n",
       "37                       (0.8784090054085895, 0.0)       15008  \n",
       "38                       (0.8730414174031381, 0.0)       18980  \n",
       "39                       (0.8732637126419409, 0.0)       24004  \n",
       "40                       (0.8794094010170328, 0.0)       30358  \n",
       "41                       (0.8800273035855573, 0.0)       38393  \n",
       "42                       (0.8849452356010143, 0.0)       48555  \n",
       "43                       (0.8866827324602018, 0.0)       61407  \n",
       "44                       (0.8809206579017885, 0.0)       77660  \n",
       "45                       (0.8810319181471701, 0.0)       98216  \n",
       "46                       (0.8874471529935656, 0.0)      124212  \n",
       "47                        (0.884264805946993, 0.0)      157089  \n",
       "48                       (0.8819350314953858, 0.0)      198668  \n",
       "49                       (0.8851309570895478, 0.0)      209846  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'LC-metric-results/RNA/run{run}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPUforge",
   "language": "python",
   "name": "tfgpuforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
